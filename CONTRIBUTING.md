# no-magic 기여 가이드

기여에 관심을 가져줘서 고마움. 이 문서가 긴 이유는 기준이 높기 때문임. 이 저장소의 모든 스크립트는 알고리즘을 처음 이해하려는 사람들이 읽는 것임 — 당신의 코드가 그들의 교사임. 제출 전에 반드시 전부 읽을 것.

---

## 양보 불가 제약조건

가이드라인이 아님. 하드 요구사항임. 이 중 하나라도 위반하는 PR은 리뷰 없이 닫힘.

| 제약조건 | 규칙 |
|---|---|
| **단일 파일** | 모든 스크립트는 하나의 `.py` 파일임. 로컬 import 없음, `utils.py` 없음, 동반 파일 없음. |
| **의존성 제로** | Python 표준 라이브러리만 사용. `pip install`이 필요하면 여기에 속하지 않음. 허용 모듈: `os`, `math`, `random`, `json`, `struct`, `urllib`, `collections`, `itertools`, `functools`, `string`, `hashlib`, `time`. |
| **학습과 추론** | 모든 스크립트는 완전한 학습 루프와 추론/생성을 모두 포함함. 독자가 전체 라이프사이클을 볼 수 있어야 함. |
| **수 분 내 실행** | **M시리즈 Mac에서 7분 미만** 또는 **2019년형 Intel i5에서 10분 미만**. GPU 불필요. |
| **자체 포함 데이터** | 데이터셋은 첫 실행 시 `urllib`로 자동 다운로드되고 로컬에 캐싱됨. 수동 다운로드 단계 없음. 최대 5MB. |
| **재현 가능** | 모든 스크립트 상단에 `random.seed(42)`. 같은 입력, 같은 출력. |
| **주석 필수** | 모든 스크립트는 아래 설명된 주석 표준을 따라야 함. PR이 거절되는 가장 흔한 이유임. |

**PR이 `requirements.txt`를 추가하면 닫힘.**

---

## 원하는 기여

### 새 스크립트

널리 사용되지만 제대로 이해되지 않는 알고리즘의 새로운 단일파일 구현을 환영함. 좋은 후보는 다음 특징을 공유함:

- 현대 AI/ML 인프라의 상당 부분을 구동하는 알고리즘일 것.
- 대부분의 실무자가 내부를 이해하지 못한 채 라이브러리 추상화를 통해 사용하고 있을 것.
- CPU에서 10분 미만으로 작은 데이터셋에서 의미 있게 시연할 수 있을 것.
- 저장소에 이미 존재하지 않을 것.

새 스크립트를 작성하기 전에, 알고리즘이 무엇인지, 무엇을 가르치는지, 왜 여기에 속하는지 설명하는 이슈를 먼저 열 것. 컬렉션에 맞지 않는 것에 시간을 투자하는 것을 방지해줌.

### 기존 스크립트 개선

다음과 같은 방식으로 기존 스크립트를 개선하는 PR을 환영함:

- **더 나은 주석**: 더 명확한 설명, 더 나은 직관, 개선된 수학-코드 매핑.
- **버그 수정**: 잘못된 구현, 수치 불안정성, 재현성 문제.
- **가독성 개선**: 더 명확한 변수 이름, 더 나은 코드 구조, 혼란스러운 패턴 제거.
- **제약조건 내 성능 개선**: 의존성 추가나 가독성 희생 없이 스크립트를 더 빠르게 만드는 것. 가독성이 항상 성능보다 우선임.

### 원하지 않는 기여

- 외부 라이브러리를 래핑하거나 호출하는 스크립트 (NumPy 같은 "가벼운" 것도 포함).
- 비례적 명확성 없이 복잡성만 추가하는 "개선된" 버전.
- 공유 유틸리티를 공통 모듈로 추출하는 리팩터링 — 각 스크립트는 독립적임.
- 노트북, 블로그 포스트, 문서만 있는 PR (이런 것은 이슈를 열어 논의할 것).
- 학습 없이 순전파만 시연하는 스크립트 (`microattention.py` 같은 비교 스크립트는 문서화된 예외임).

---

## 주석 표준

대부분의 첫 기여자가 조정이 필요한 부분임. 줄 수나 코드 우아함을 최적화하는 것이 **아님**. 독자의 이해를 최적화하는 것임. 의욕 있는 엔지니어가 스크립트를 열고 위에서 아래로 읽을 수 있어야 함 — 가이드 투어처럼 — 논문, 교과서, 외부 참조 없이.

*더 적은 줄이 목표가 아님. 더 적은 혼란의 순간이 목표임.*

### 필수 주석 유형

스크립트에 다음 모든 항목이 포함되어야 함:

**1. 파일 테제**

첫 줄은 스크립트가 한 문장으로 무엇을 증명하는지 기술하는 docstring임. 이것이 스크립트의 존재 이유임.

```python
"""
The complete BPE tokenization algorithm: learning merges from a corpus, encoding text to
tokens, and decoding tokens back to text — in pure Python with zero dependencies.
"""
```

**2. 섹션 헤더**

주요 단계를 구분하는 블록 주석. 이 헤더만 훑어봐도 코드를 읽지 않고 스크립트의 구조를 이해할 수 있어야 함.

```python
# === DATA LOADING ===
# 학습 코퍼스를 가져와서 준비.

# === MODEL DEFINITION ===
# 인코더와 디코더 네트워크를 정의.

# === TRAINING LOOP ===
# 선형 LR 감소와 함께 Adam으로 모델을 학습.

# === INFERENCE ===
# 학습된 모델에서 새로운 샘플을 생성.
```

**3. "왜" 주석**

자명하지 않은 결정의 이유를 설명함. 코드는 *무엇이* 일어나는지 보여줌. 주석은 *왜* 이렇게 하는지, 다르게 했으면 무엇이 깨지거나 저하되는지 설명함.

```python
# We use RMSNorm instead of LayerNorm: it drops the mean subtraction and learned
# affine parameters. Fewer ops, fewer params, and modern architectures (LLaMA, Gemma)
# have shown it works just as well.
```

**4. 수학-코드 매핑**

코드가 알려진 방정식을 구현하는 곳에서, 방정식을 보여주고 변수를 명시적으로 매핑함. 독자가 어떤 변수가 논문의 어떤 기호에 해당하는지 추측할 필요가 없어야 함.

```python
# Reparameterization trick: z = μ + σ * ε, where ε ~ N(0,1)
# This lets gradients flow through the sampling operation because
# the randomness (epsilon) is external to the computation graph.
epsilon = random.gauss(0, 1)
z = mu + exp(0.5 * log_var) * epsilon
```

**5. 직관 주석**

기법이 *왜* 작동하는지에 대한 간략한 설명. 어떻게가 아님. 위키피디아 한 번 안 가도 되게 해주는 주석임. 두 문장으로 설명할 수 있을 만큼 깊이 이해하고 있다면, 논문 링크보다 가치 있음.

```python
# The update gate z_t acts as a "gradient highway": when z_t ≈ 1, the new hidden
# state is just a copy of the previous one (h_t = h_{t-1}), so gradients flow
# backward through time without multiplication by weight matrices. This is why
# GRUs don't suffer from vanishing gradients the way vanilla RNNs do.
```

**6. 이정표 주석**

교육적 이유로 단순화한 선택을 한 곳에서, 그것을 표시하고 프로덕션 시스템이 어떻게 다르게 하는지 기록함. 독자가 교육용 패턴을 모범 사례로 오해하는 것을 방지함.

```python
# In production, you'd use Generalized Advantage Estimation (GAE) here for lower
# variance. We use simple (reward - baseline) to keep the PPO core visible without
# the GAE machinery obscuring it.
```

**7. 자명한 주석 금지**

코드가 자명하면 코드가 스스로 말하게 할 것. 모든 주석은 코드만으로는 전달하지 못하는 정보를 추가해서 자리를 정당화해야 함.

```python
# 나쁨 — 코드를 다시 말함
x = x + 1  # x를 1 증가

# 나쁨 — 더 많은 단어로 코드를 다시 말함
total = sum(losses)  # 모든 loss를 합산

# 좋음 — 왜인지 설명함
total = sum(losses) / len(losses)  # 합이 아니라 시퀀스 길이로 평균을 내서
                                    # loss가 문서 길이에 무관하게 스케일 불변이 됨
```

### 주석 밀도

대략 30-40%의 줄이 주석이나 빈 줄이 되는 것을 목표로 함. 이것은 엄격한 지표가 아님 — 밀집된 수학 섹션은 더 많은 설명이 필요하고, 데이터 로딩 보일러플레이트는 덜 필요함. 실제 테스트는 주관적이지만 엄격함: *일반적인 ML 지식을 가진 의욕 있는 엔지니어가 이 파일을 한 번에 위에서 아래로 읽고 알고리즘을 이해할 수 있는가?*

---

## 코드 스타일

### 일반 원칙

- **영리함보다 가독성.** 3줄짜리 명시적 루프가 1줄짜리 컴프리헨션보다 명확하면, 루프를 사용할 것.
- **중첩보다 평탄.** 깊은 중첩을 피할 것. 서술적 이름의 헬퍼 함수로 추출할 것.
- **서술적 이름.** 변수는 나타내는 것의 이름을 따서 명명하고, 간결함을 위해 축약하지 말 것. `lr`이 아니라 `learning_rate`, `hd`가 아니라 `hidden_dim`을 사용할 것. 예외: 관례적 수학 표기(`x`, `z`, `mu`, `sigma`), 루프 인덱스(`i`, `j`, `t`), ML에서 보편적으로 이해되는 약어(`embd`, `attn`, `mlp`).
- **함수는 무엇을 서술하고, 어떻게가 아님.** 함수 이름은 *무엇을* 계산하는지를 따서 명명할 것: `rmsnorm`, `softmax`, `linear`. `normalize_v2`나 `process_data`가 아님.
- **일관된 구조.** 섹션 순서를 따를 것: imports → 상수/하이퍼파라미터 → 데이터 로딩 → 모델 정의 → 학습 루프 → 추론.

### 포맷팅

- 4칸 들여쓰기 사용.
- 최대 줄 길이 100자. 긴 줄은 가독성을 위해 분리할 것.
- 함수 내 논리적 블록 사이에 빈 줄 하나. 최상위 정의 사이에 빈 줄 둘.
- 후행 공백 없음.
- 파일 끝에 개행 하나.

### Python 관행

- 함수 시그니처에서 가독성에 도움이 되는 경우 type hint를 사용하되, 자명한 타입을 과도하게 어노테이션하지 말 것.
- 포맷된 출력에는 `f-string`을 선호할 것.
- 어떤 랜덤성보다 앞서, 상단에 `random.seed(42)`를 사용할 것.
- 가능하면 전역 가변 상태를 피할 것. 전역이 필요한 경우(`microgpt.py`의 `state_dict`처럼), 왜인지 주석을 달 것.
- 알고리즘이 근본적으로 요구하지 않는 한 클래스를 사용하지 말 것 (예: autograd를 위한 `Value`). 함수와 일반 데이터 구조를 선호할 것.

---

## Pull Request 제출

### 시작 전

1. **기존 이슈와 구현 계획을 확인할 것.** `implementation.md` 파일이 모든 스크립트를 상세한 스펙과 함께 문서화하고 있음.
2. **새 알고리즘 아이디어의 경우**, 먼저 이슈를 열 것. 알고리즘, 무엇을 가르치는지, 사용할 데이터셋, 예상 줄 수를 설명할 것. 코드 작성 전에 승인을 기다릴 것.
3. **기존 스크립트 개선의 경우**, 무엇을 왜 변경하는지 설명하는 이슈를 열 것. 작은 수정(오타, 수치 버그)은 바로 PR로 가도 됨.

### 스크립트 작성

1. 알고리즘에 대한 스펙이 `implementation.md`에 있으면 거기서 시작할 것.
2. 단일 파일로 완전한 스크립트를 작성할 것.
3. 자기 머신에서 처음부터 끝까지 실행할 것. 10분 미만으로 완료되는지 확인할 것.
4. 새 디렉토리에서 다시 실행할 것 (캐싱된 데이터 파일 삭제) 자동 다운로드가 작동하는지 확인할 것.
5. 위의 주석 표준과 비교하여 자기 주석을 검토할 것. 솔직하게 — 알고리즘을 처음 보는 사람이 *본인이라면* 이 코드를 이해할 수 있겠는가?

### PR 요구사항

Pull request에 포함해야 하는 것:

- 올바른 티어 디렉토리에 배치된 **스크립트 파일** (`01-foundations/`, `02-alignment/`, 또는 `03-systems/`).
- 다음을 포함하는 **PR 설명**:
  - 알고리즘 이름과 한 문장 요약.
  - 사용한 데이터셋과 가져오는 방법.
  - 총 줄 수와 대략적인 주석 밀도.
  - 자기 머신에서의 실행 시간 (CPU 모델 + 시간).
  - 샘플 출력 (학습 진행 상황과 추론 결과 몇 줄을 복사-붙여넣기).

Pull request에 포함하지 **않아야** 하는 것:

- 다른 스크립트의 변경 (교차 버그 수정이 아닌 한).
- 확립된 구조 밖의 새 디렉토리.
- 단일 `.py` 스크립트 외의 모든 파일 (스크립트별 README 없음, 노트북 없음, 테스트 파일 없음).
- `CONTRIBUTING.md` 변경 (이것은 이슈를 열어 논의할 것).

### 리뷰 프로세스

1. **자동 검사**: 스크립트가 `python script.py`로 실행되고 깨끗하게 종료되어야 함. 인자 없음, 환경 변수 없음, 수동 설정 없음.
2. **제약조건 검증**: 단일 파일, 의존성 제로, 10분 미만, 재현 가능한 출력.
3. **주석 리뷰**: 리뷰에서 가장 철저한 부분임. 주석 품질, 누락된 직관 설명, 불명확한 수학 매핑에 대한 피드백을 예상할 것. 트집 잡기가 아님 — 프로젝트의 핵심 품질 기준임.
4. **정확성 리뷰**: 알고리즘이 올바르게 구현되어야 함. 단순화는 됨. 틀리면 안 됨. 구현이 표준 알고리즘에서 벗어나면, 벗어난 이유를 설명하는 이정표 주석이 있어야 함.
5. **가독성 리뷰**: "한 번에 읽기" 테스트. 리뷰어가 스크립트를 위에서 아래로 읽으며 멈춰서 생각해야 했던 모든 지점을 기록함. 너무 많으면 주석을 추가하거나 구조를 변경하도록 요청받게 됨.

최소 한 차례 수정을 예상할 것. 이것은 정상이며 코드 품질의 반영이 아님 — 교육적 독자를 위해 작성하는 것의 본질임.

---

## 저작자 표시와 라이선스

- 모든 기여는 MIT 라이선스 하에 이루어짐.
- 스크립트가 특정 논문, 블로그 포스트, 기존 구현에서 영감을 받았다면, 파일 상단의 테제 docstring 바로 뒤에 주석으로 인용할 것.
- 다른 저장소에서 코드를 복사하지 말 것, MIT 라이선스여도. 직접 구현을 작성할 것. 정확성 검증을 위해 다른 구현을 참조할 수 있지만, 코드는 원본이어야 함.
- 스크립트가 Karpathy의 작업(micrograd, makemore, microgpt)과 유사한 영역을 다루는 경우, 이미 존재하는 것을 복제하는 것이 아니라 차별화된 교육적 가치를 제공하는지 확인할 것. 이를 어떻게 처리하는지는 `implementation.md`를 참조할 것.

```python
"""
Direct Preference Optimization: training a language model to align with human preferences
without a separate reward model — in pure Python with zero dependencies.
"""
# Reference: Rafailov et al., "Direct Preference Optimization: Your Language Model is
# Secretly a Reward Model" (2023). https://arxiv.org/abs/2305.18290
# Inspired by the DPO implementation in TRL, but rewritten from scratch for clarity.
```

---

## 행동 강령

- 이슈와 리뷰에서 존중할 것.
- 선의를 가정할 것. 기여자들은 서로 다른 배경과 경험 수준에서 옴.
- 사람이 아니라 코드와 주석을 비판할 것.
- 리뷰 결정에 동의하지 않으면 자기 논리를 설명할 것. 메인테이너가 여전히 동의하지 않으면 결정을 품위 있게 수용할 것.

---

## 빠른 참조 체크리스트

제출 전에 모든 항목을 확인할 것:

**실행**
- [ ] `python script.py`가 인자 없이 실행되고 깨끗하게 종료됨
- [ ] Python 표준 라이브러리 외 import 없음
- [ ] 상단에 `random.seed(42)`
- [ ] M시리즈 Mac에서 7분 미만으로 완료됨 (또는 2019 Intel i5에서 10분 미만)
- [ ] 학습 진행 상황 출력 (step 번호, loss)
- [ ] 학습된 모델을 보여주는 추론 결과 출력
- [ ] `docs/implementation.md`에 정의된 이 스크립트의 성공 기준을 충족함

**Autograd & 수치 안정성** (scalar autograd를 사용하는 스크립트용)
- [ ] `Value` class가 `docs/autograd-interface.md`의 표준 인터페이스를 구현함
- [ ] Value class 뒤에 autograd 설명 블록이 있음 (스크립트별 차이점을 문서화)
- [ ] 안정적 softmax: 설명 주석과 함께 `exp(x - max(x))` 패턴 사용
- [ ] 클리핑된 log 확률: 주석과 함께 `log()` 전에 `max(p, 1e-10)` 사용
- [ ] Adam epsilon: 주석과 함께 분모에 `1e-8` 사용
- [ ] 테스트 벡터 통과 (`docs/autograd-interface.md`에서)

**주석 (양보 불가)**
- [ ] 파일이 한 문장 테제 docstring으로 시작함
- [ ] 섹션 헤더(`# === SECTION ===`)가 주요 단계를 구분함
- [ ] 모든 자명하지 않은 블록에 "왜" 주석이 있음
- [ ] 핵심 방정식에 수학-코드 매핑 주석이 있음
- [ ] 핵심 알고리즘 개념마다 최소 하나의 직관 주석이 있음
- [ ] 단순화한 선택에 이정표 주석이 표시됨
- [ ] 자명하거나 중복된 주석 없음
- [ ] 주석 밀도 약 30-40%

**가독성**
- [ ] "한 번에 읽기" 테스트 통과
- [ ] 변수 이름이 서술적이고 일관적임
- [ ] 함수가 계산하는 것을 따서 명명됨
- [ ] 불필요한 복잡성이나 영리함 없음

**기타**
- [ ] 파일이 올바른 티어 디렉토리에 배치됨 (`01-foundations/`, `02-alignment/`, 또는 `03-systems/`)
- [ ] PR 설명에 실행 시간, 줄 수, 샘플 출력이 포함됨
- [ ] 추가 파일 포함 없음
- [ ] 참조된 논문이나 구현에 대한 저작자 표시 주석

---

*제약이 곧 제품임. 주석이 곧 커리큘럼임. 함께 만들어줘서 고마움.*
